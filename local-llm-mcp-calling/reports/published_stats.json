{
  "model_rankings": [
    {
      "model": "zai-org/glm-4.7-flash",
      "short_name": "glm-4.7-flash",
      "params_string": "30B",
      "disk_gb": 16.9,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 97.0,
      "ag_l2": 89.3,
      "ag_overall": 95.4,
      "ss_l0": 100.0,
      "ss_l1": 85.2,
      "ss_l2": 33.3,
      "ss_overall": 72.8,
      "ag_rank": 1,
      "ss_rank": 11
    },
    {
      "model": "qwen/qwen3-coder-next",
      "short_name": "qwen3-coder-next",
      "params_string": "80B",
      "disk_gb": 45.2,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 100.0,
      "ag_l2": 85.7,
      "ag_overall": 95.2,
      "ss_l0": 100.0,
      "ss_l1": 93.5,
      "ss_l2": 38.1,
      "ss_overall": 77.2,
      "ag_rank": 2,
      "ss_rank": 4
    },
    {
      "model": "mistralai/devstral-small-2-2512",
      "short_name": "devstral-small-2-2512",
      "params_string": "24B",
      "disk_gb": 12.4,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 100.0,
      "ag_l2": 82.1,
      "ag_overall": 94.0,
      "ss_l0": 100.0,
      "ss_l1": 93.5,
      "ss_l2": 44.0,
      "ss_overall": 79.2,
      "ag_rank": 3,
      "ss_rank": 2
    },
    {
      "model": "mistralai/ministral-3-14b-reasoning",
      "short_name": "ministral-3-14b-reasoning",
      "params_string": "14B",
      "disk_gb": 8.5,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 100.0,
      "ag_l2": 82.1,
      "ag_overall": 94.0,
      "ss_l0": 100.0,
      "ss_l1": 91.0,
      "ss_l2": 40.5,
      "ss_overall": 77.2,
      "ag_rank": 3,
      "ss_rank": 4
    },
    {
      "model": "qwen/qwen3.5-35b-a3b",
      "short_name": "qwen3.5-35b-a3b",
      "params_string": "35B-A3B",
      "disk_gb": 20.6,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 100.0,
      "ag_l2": 82.1,
      "ag_overall": 94.0,
      "ss_l0": 100.0,
      "ss_l1": 85.2,
      "ss_l2": 26.2,
      "ss_overall": 70.5,
      "ag_rank": 3,
      "ss_rank": 13
    },
    {
      "model": "mistralai/magistral-small-2509",
      "short_name": "magistral-small-2509",
      "params_string": "24B",
      "disk_gb": 14.2,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 98.5,
      "ag_l2": 77.6,
      "ag_overall": 92.0,
      "ss_l0": 100.0,
      "ss_l1": 92.0,
      "ss_l2": 41.7,
      "ss_overall": 77.9,
      "ag_rank": 6,
      "ss_rank": 3
    },
    {
      "model": "qwen/qwen3-coder-30b",
      "short_name": "qwen3-coder-30b",
      "params_string": "30B-A3B",
      "disk_gb": 17.4,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 100.0,
      "ag_l2": 75.0,
      "ag_overall": 91.7,
      "ss_l0": 100.0,
      "ss_l1": 93.5,
      "ss_l2": 29.8,
      "ss_overall": 74.4,
      "ag_rank": 7,
      "ss_rank": 7
    },
    {
      "model": "microsoft/phi-4-reasoning-plus",
      "short_name": "phi-4-reasoning-plus",
      "params_string": "15B",
      "disk_gb": 8.4,
      "tool_trained": false,
      "ag_l0": 100.0,
      "ag_l1": 96.5,
      "ag_l2": 77.6,
      "ag_overall": 91.4,
      "ss_l0": 36.4,
      "ss_l1": 61.7,
      "ss_l2": 7.1,
      "ss_overall": 35.1,
      "ag_rank": 8,
      "ss_rank": 21
    },
    {
      "model": "openai/gpt-oss-20b",
      "short_name": "gpt-oss-20b",
      "params_string": "20B",
      "disk_gb": 11.3,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 92.0,
      "ag_l2": 81.2,
      "ag_overall": 91.1,
      "ss_l0": 100.0,
      "ss_l1": 85.2,
      "ss_l2": 36.9,
      "ss_overall": 74.0,
      "ag_rank": 9,
      "ss_rank": 9
    },
    {
      "model": "qwen/qwen3-4b-thinking-2507",
      "short_name": "qwen3-4b-thinking-2507",
      "params_string": "4B",
      "disk_gb": 2.3,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 100.0,
      "ag_l2": 67.9,
      "ag_overall": 89.3,
      "ss_l0": 81.8,
      "ss_l1": 30.2,
      "ss_l2": 7.1,
      "ss_overall": 39.7,
      "ag_rank": 10,
      "ss_rank": 18
    },
    {
      "model": "liquid/lfm2-24b-a2b",
      "short_name": "lfm2-24b-a2b",
      "params_string": "64x1.3B",
      "disk_gb": 13.4,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 92.0,
      "ag_l2": 75.4,
      "ag_overall": 89.1,
      "ss_l0": 100.0,
      "ss_l1": 89.0,
      "ss_l2": 57.1,
      "ss_overall": 82.0,
      "ag_rank": 11,
      "ss_rank": 1
    },
    {
      "model": "essentialai/rnj-1",
      "short_name": "rnj-1",
      "params_string": "8.3B",
      "disk_gb": 4.8,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 100.0,
      "ag_l2": 64.8,
      "ag_overall": 88.3,
      "ss_l0": 100.0,
      "ss_l1": 83.7,
      "ss_l2": 26.2,
      "ss_overall": 70.0,
      "ag_rank": 12,
      "ss_rank": 14
    },
    {
      "model": "ibm/granite-4-h-tiny",
      "short_name": "granite-4-h-tiny",
      "params_string": "7B",
      "disk_gb": 3.9,
      "tool_trained": true,
      "ag_l0": 98.6,
      "ag_l1": 91.5,
      "ag_l2": 69.9,
      "ag_overall": 86.7,
      "ss_l0": 100.0,
      "ss_l1": 79.7,
      "ss_l2": 42.6,
      "ss_overall": 74.1,
      "ag_rank": 13,
      "ss_rank": 8
    },
    {
      "model": "nvidia/nemotron-3-nano",
      "short_name": "nemotron-3-nano",
      "params_string": "30B",
      "disk_gb": 22.8,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 98.5,
      "ag_l2": 59.3,
      "ag_overall": 85.9,
      "ss_l0": 100.0,
      "ss_l1": 83.5,
      "ss_l2": 7.1,
      "ss_overall": 63.5,
      "ag_rank": 14,
      "ss_rank": 15
    },
    {
      "model": "google/gemma-3-12b",
      "short_name": "gemma-3-12b",
      "params_string": "12B",
      "disk_gb": 7.6,
      "tool_trained": false,
      "ag_l0": 100.0,
      "ag_l1": 91.0,
      "ag_l2": 66.7,
      "ag_overall": 85.9,
      "ss_l0": 100.0,
      "ss_l1": 84.2,
      "ss_l2": 31.9,
      "ss_overall": 72.0,
      "ag_rank": 14,
      "ss_rank": 12
    },
    {
      "model": "baidu/ernie-4.5-21b-a3b",
      "short_name": "ernie-4.5-21b-a3b",
      "params_string": "21B-A3B",
      "disk_gb": 12.6,
      "tool_trained": false,
      "ag_l0": 100.0,
      "ag_l1": 100.0,
      "ag_l2": 57.6,
      "ag_overall": 85.9,
      "ss_l0": 100.0,
      "ss_l1": 85.2,
      "ss_l2": 36.2,
      "ss_overall": 73.8,
      "ag_rank": 14,
      "ss_rank": 10
    },
    {
      "model": "mistralai/ministral-3-3b",
      "short_name": "ministral-3-3b",
      "params_string": "3B",
      "disk_gb": 2.8,
      "tool_trained": true,
      "ag_l0": 100.0,
      "ag_l1": 92.0,
      "ag_l2": 63.2,
      "ag_overall": 85.1,
      "ss_l0": 100.0,
      "ss_l1": 92.5,
      "ss_l2": 35.5,
      "ss_overall": 76.0,
      "ag_rank": 17,
      "ss_rank": 6
    },
    {
      "model": "zai-org/glm-4.6v-flash",
      "short_name": "glm-4.6v-flash",
      "params_string": "9.4B",
      "disk_gb": 7.4,
      "tool_trained": true,
      "ag_l0": 90.9,
      "ag_l1": 83.5,
      "ag_l2": 67.1,
      "ag_overall": 80.5,
      "ss_l0": 90.9,
      "ss_l1": 45.2,
      "ss_l2": 19.0,
      "ss_overall": 51.7,
      "ag_rank": 18,
      "ss_rank": 17
    },
    {
      "model": "bytedance/seed-oss-36b",
      "short_name": "seed-oss-36b",
      "params_string": "36B",
      "disk_gb": 20.3,
      "tool_trained": true,
      "ag_l0": 86.8,
      "ag_l1": 71.3,
      "ag_l2": 41.7,
      "ag_overall": 66.6,
      "ss_l0": 77.7,
      "ss_l1": 76.7,
      "ss_l2": 33.3,
      "ss_overall": 62.6,
      "ag_rank": 19,
      "ss_rank": 16
    },
    {
      "model": "qwen/qwen2.5-coder-32b",
      "short_name": "qwen2.5-coder-32b",
      "params_string": "32B",
      "disk_gb": 18.5,
      "tool_trained": false,
      "ag_l0": 72.7,
      "ag_l1": 40.0,
      "ag_l2": 17.9,
      "ag_overall": 43.5,
      "ss_l0": 63.6,
      "ss_l1": 43.5,
      "ss_l2": 7.1,
      "ss_overall": 38.1,
      "ag_rank": 20,
      "ss_rank": 20
    },
    {
      "model": "deepseek/deepseek-r1-0528-qwen3-8b",
      "short_name": "deepseek-r1-0528-qwen3-8b",
      "params_string": "8B",
      "disk_gb": 4.7,
      "tool_trained": false,
      "ag_l0": 97.3,
      "ag_l1": 22.0,
      "ag_l2": 0.0,
      "ag_overall": 39.8,
      "ss_l0": 90.9,
      "ss_l1": 26.7,
      "ss_l2": 0.0,
      "ss_overall": 39.2,
      "ag_rank": 21,
      "ss_rank": 19
    }
  ],
  "level_comparison": {
    "L0": {
      "ss_score_mean": 92.4,
      "ag_score_mean": 97.4,
      "lift": 5.0,
      "ss_pass_rate_mean": 92.6,
      "ag_pass_rate_mean": 97.8
    },
    "L1": {
      "ss_score_mean": 76.2,
      "ag_score_mean": 88.8,
      "lift": 12.6,
      "ss_pass_rate_mean": 73.3,
      "ag_pass_rate_mean": 89.5
    },
    "L2": {
      "ss_score_mean": 28.6,
      "ag_score_mean": 65.9,
      "lift": 37.3,
      "ss_pass_rate_mean": 2.0,
      "ag_pass_rate_mean": 49.7
    }
  },
  "overall_lift": {
    "mean": 18.3,
    "median": 16.8
  },
  "per_model_lift": [
    {
      "model": "microsoft/phi-4-reasoning-plus",
      "short_name": "phi-4-reasoning-plus",
      "ss_overall": 35.1,
      "ag_overall": 91.4,
      "lift": 56.3
    },
    {
      "model": "qwen/qwen3-4b-thinking-2507",
      "short_name": "qwen3-4b-thinking-2507",
      "ss_overall": 39.7,
      "ag_overall": 89.3,
      "lift": 49.6
    },
    {
      "model": "zai-org/glm-4.6v-flash",
      "short_name": "glm-4.6v-flash",
      "ss_overall": 51.7,
      "ag_overall": 80.5,
      "lift": 28.8
    },
    {
      "model": "qwen/qwen3.5-35b-a3b",
      "short_name": "qwen3.5-35b-a3b",
      "ss_overall": 70.5,
      "ag_overall": 94.0,
      "lift": 23.5
    },
    {
      "model": "zai-org/glm-4.7-flash",
      "short_name": "glm-4.7-flash",
      "ss_overall": 72.8,
      "ag_overall": 95.4,
      "lift": 22.6
    },
    {
      "model": "nvidia/nemotron-3-nano",
      "short_name": "nemotron-3-nano",
      "ss_overall": 63.5,
      "ag_overall": 85.9,
      "lift": 22.4
    },
    {
      "model": "essentialai/rnj-1",
      "short_name": "rnj-1",
      "ss_overall": 70.0,
      "ag_overall": 88.3,
      "lift": 18.3
    },
    {
      "model": "qwen/qwen3-coder-next",
      "short_name": "qwen3-coder-next",
      "ss_overall": 77.2,
      "ag_overall": 95.2,
      "lift": 18.0
    },
    {
      "model": "qwen/qwen3-coder-30b",
      "short_name": "qwen3-coder-30b",
      "ss_overall": 74.4,
      "ag_overall": 91.7,
      "lift": 17.3
    },
    {
      "model": "openai/gpt-oss-20b",
      "short_name": "gpt-oss-20b",
      "ss_overall": 74.0,
      "ag_overall": 91.1,
      "lift": 17.1
    },
    {
      "model": "mistralai/ministral-3-14b-reasoning",
      "short_name": "ministral-3-14b-reasoning",
      "ss_overall": 77.2,
      "ag_overall": 94.0,
      "lift": 16.8
    },
    {
      "model": "mistralai/devstral-small-2-2512",
      "short_name": "devstral-small-2-2512",
      "ss_overall": 79.2,
      "ag_overall": 94.0,
      "lift": 14.8
    },
    {
      "model": "mistralai/magistral-small-2509",
      "short_name": "magistral-small-2509",
      "ss_overall": 77.9,
      "ag_overall": 92.0,
      "lift": 14.1
    },
    {
      "model": "google/gemma-3-12b",
      "short_name": "gemma-3-12b",
      "ss_overall": 72.0,
      "ag_overall": 85.9,
      "lift": 13.9
    },
    {
      "model": "ibm/granite-4-h-tiny",
      "short_name": "granite-4-h-tiny",
      "ss_overall": 74.1,
      "ag_overall": 86.7,
      "lift": 12.6
    },
    {
      "model": "baidu/ernie-4.5-21b-a3b",
      "short_name": "ernie-4.5-21b-a3b",
      "ss_overall": 73.8,
      "ag_overall": 85.9,
      "lift": 12.1
    },
    {
      "model": "mistralai/ministral-3-3b",
      "short_name": "ministral-3-3b",
      "ss_overall": 76.0,
      "ag_overall": 85.1,
      "lift": 9.1
    },
    {
      "model": "liquid/lfm2-24b-a2b",
      "short_name": "lfm2-24b-a2b",
      "ss_overall": 82.0,
      "ag_overall": 89.1,
      "lift": 7.1
    },
    {
      "model": "qwen/qwen2.5-coder-32b",
      "short_name": "qwen2.5-coder-32b",
      "ss_overall": 38.1,
      "ag_overall": 43.5,
      "lift": 5.4
    },
    {
      "model": "bytedance/seed-oss-36b",
      "short_name": "seed-oss-36b",
      "ss_overall": 62.6,
      "ag_overall": 66.6,
      "lift": 4.0
    },
    {
      "model": "deepseek/deepseek-r1-0528-qwen3-8b",
      "short_name": "deepseek-r1-0528-qwen3-8b",
      "ss_overall": 39.2,
      "ag_overall": 39.8,
      "lift": 0.6
    }
  ],
  "per_level_analysis": {
    "ag_l0_100_count": 16,
    "ag_l1_100_count": 8,
    "ag_l1_median": 97.0,
    "ag_l2_median": 69.9,
    "ag_l2_range_pp": 89.3,
    "ag_l2_above_85_count": 2,
    "l2_ss_pass_rate_mean": 2.0,
    "l2_ss_passers": [
      {
        "model": "liquid/lfm2-24b-a2b",
        "short_name": "lfm2-24b-a2b",
        "ss_l2_pass_rate": 42.9
      }
    ]
  },
  "tool_trained_vs_control": {
    "tool_trained": {
      "n": 16,
      "ag_mean": 88.7,
      "ag_range_min": 66.6,
      "ag_range_max": 95.4,
      "ag_std_dev": 7.2,
      "ss_mean": 70.2
    },
    "control": {
      "n": 5,
      "ag_mean": 69.3,
      "ag_range_min": 39.8,
      "ag_range_max": 91.4,
      "ag_std_dev": 25.4,
      "ss_mean": 51.6
    },
    "ag_delta": 19.4,
    "ss_delta": 18.5
  },
  "size_tiers": {
    "Tiny (3-4B)": {
      "n": 2,
      "models": [
        "qwen3-4b-thinking-2507",
        "ministral-3-3b"
      ],
      "ag_mean": 87.2,
      "ag_range_min": 85.1,
      "ag_range_max": 89.3
    },
    "Small (7-9.4B)": {
      "n": 4,
      "models": [
        "rnj-1",
        "granite-4-h-tiny",
        "glm-4.6v-flash",
        "deepseek-r1-0528-qwen3-8b"
      ],
      "ag_mean": 73.8,
      "ag_range_min": 39.8,
      "ag_range_max": 88.3
    },
    "Medium (12-15B)": {
      "n": 3,
      "models": [
        "ministral-3-14b-reasoning",
        "phi-4-reasoning-plus",
        "gemma-3-12b"
      ],
      "ag_mean": 90.4,
      "ag_range_min": 85.9,
      "ag_range_max": 94.0
    },
    "Large (20-24B)": {
      "n": 5,
      "models": [
        "devstral-small-2-2512",
        "magistral-small-2509",
        "gpt-oss-20b",
        "lfm2-24b-a2b",
        "ernie-4.5-21b-a3b"
      ],
      "ag_mean": 90.4,
      "ag_range_min": 85.9,
      "ag_range_max": 94.0
    },
    "XL (30-36B)": {
      "n": 6,
      "models": [
        "glm-4.7-flash",
        "qwen3.5-35b-a3b",
        "qwen3-coder-30b",
        "nemotron-3-nano",
        "seed-oss-36b",
        "qwen2.5-coder-32b"
      ],
      "ag_mean": 79.5,
      "ag_range_min": 43.5,
      "ag_range_max": 95.4
    },
    "XXL (80B)": {
      "n": 1,
      "models": [
        "qwen3-coder-next"
      ],
      "ag_mean": 95.2,
      "ag_range_min": 95.2,
      "ag_range_max": 95.2
    }
  },
  "qwen3_4b_analysis": {
    "score": 89.3,
    "beaten_models": [
      {
        "model": "liquid/lfm2-24b-a2b",
        "short_name": "lfm2-24b-a2b",
        "params_string": "64x1.3B",
        "ag_overall": 89.1
      },
      {
        "model": "essentialai/rnj-1",
        "short_name": "rnj-1",
        "params_string": "8.3B",
        "ag_overall": 88.3
      },
      {
        "model": "ibm/granite-4-h-tiny",
        "short_name": "granite-4-h-tiny",
        "params_string": "7B",
        "ag_overall": 86.7
      },
      {
        "model": "nvidia/nemotron-3-nano",
        "short_name": "nemotron-3-nano",
        "params_string": "30B",
        "ag_overall": 85.9
      },
      {
        "model": "google/gemma-3-12b",
        "short_name": "gemma-3-12b",
        "params_string": "12B",
        "ag_overall": 85.9
      },
      {
        "model": "baidu/ernie-4.5-21b-a3b",
        "short_name": "ernie-4.5-21b-a3b",
        "params_string": "21B-A3B",
        "ag_overall": 85.9
      },
      {
        "model": "mistralai/ministral-3-3b",
        "short_name": "ministral-3-3b",
        "params_string": "3B",
        "ag_overall": 85.1
      },
      {
        "model": "zai-org/glm-4.6v-flash",
        "short_name": "glm-4.6v-flash",
        "params_string": "9.4B",
        "ag_overall": 80.5
      },
      {
        "model": "bytedance/seed-oss-36b",
        "short_name": "seed-oss-36b",
        "params_string": "36B",
        "ag_overall": 66.6
      },
      {
        "model": "qwen/qwen2.5-coder-32b",
        "short_name": "qwen2.5-coder-32b",
        "params_string": "32B",
        "ag_overall": 43.5
      },
      {
        "model": "deepseek/deepseek-r1-0528-qwen3-8b",
        "short_name": "deepseek-r1-0528-qwen3-8b",
        "params_string": "8B",
        "ag_overall": 39.8
      }
    ],
    "beaten_count": 11,
    "param_ratios": [
      {
        "model": "seed-oss-36b",
        "params": 36.0,
        "ratio": 9.0
      },
      {
        "model": "qwen2.5-coder-32b",
        "params": 32.0,
        "ratio": 8.0
      },
      {
        "model": "nemotron-3-nano",
        "params": 30.0,
        "ratio": 7.5
      },
      {
        "model": "lfm2-24b-a2b",
        "params": 24.0,
        "ratio": 6.0
      },
      {
        "model": "ernie-4.5-21b-a3b",
        "params": 21.0,
        "ratio": 5.2
      },
      {
        "model": "gemma-3-12b",
        "params": 12.0,
        "ratio": 3.0
      },
      {
        "model": "glm-4.6v-flash",
        "params": 9.4,
        "ratio": 2.4
      },
      {
        "model": "rnj-1",
        "params": 8.3,
        "ratio": 2.1
      },
      {
        "model": "deepseek-r1-0528-qwen3-8b",
        "params": 8.0,
        "ratio": 2.0
      },
      {
        "model": "granite-4-h-tiny",
        "params": 7.0,
        "ratio": 1.8
      },
      {
        "model": "ministral-3-3b",
        "params": 3.0,
        "ratio": 0.8
      }
    ],
    "max_param_ratio": 9.0
  },
  "disk_sizes_gb": {
    "zai-org/glm-4.7-flash": 16.9,
    "qwen/qwen3-coder-next": 45.2,
    "mistralai/devstral-small-2-2512": 12.4,
    "mistralai/ministral-3-14b-reasoning": 8.5,
    "qwen/qwen3.5-35b-a3b": 20.6,
    "mistralai/magistral-small-2509": 14.2,
    "qwen/qwen3-coder-30b": 17.4,
    "microsoft/phi-4-reasoning-plus": 8.4,
    "openai/gpt-oss-20b": 11.3,
    "qwen/qwen3-4b-thinking-2507": 2.3,
    "liquid/lfm2-24b-a2b": 13.4,
    "essentialai/rnj-1": 4.8,
    "ibm/granite-4-h-tiny": 3.9,
    "nvidia/nemotron-3-nano": 22.8,
    "google/gemma-3-12b": 7.6,
    "baidu/ernie-4.5-21b-a3b": 12.6,
    "mistralai/ministral-3-3b": 2.8,
    "zai-org/glm-4.6v-flash": 7.4,
    "bytedance/seed-oss-36b": 20.3,
    "qwen/qwen2.5-coder-32b": 18.5,
    "deepseek/deepseek-r1-0528-qwen3-8b": 4.7
  },
  "models_above_85_ag": 17,
  "qwen3_4b_improvement_ratio": 2.2
}